Grokker helps maintain this README in a VIM session by reading its own source code.

Grokker began life as a Retrieval Augmented Generation (RAG) tool for answering questions about local documents and code; we use it in developing the PromiseGrid decentralized computing platform. Grokker currently uses OpenAI API servers for its backend, but we expect that to change as we migrate AI services and grokker itself onto the grid.

Over time, grokker has grown into a swiss-army-knife for natural language processing, code and file interpretation and generation, and AI-based research and development. Its features include:

    Interactive conversation with one or more documents and/or code
    Human-in-the-loop AI-driven development (AIDDA)
    Design, research, and rapid learning
    Local vector database
    Easy VIM integration
    Chat client with named file I/O
    Able to accept and generate file content in natural language, code, structured messages, or a combination
    LLM tooling including system message inputs, token counting and embedding subcommands
